{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x1ypzczQCwy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using TensorFlow Recommenders with TFX\n",
    "\n",
    "***A tutorial to train a TensorFlow Recommenders ranking model as a [TFX pipeline](https://www.tensorflow.org/tfx).***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU9YYythm0dx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/recommenders/examples/ranking_tfx\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/recommenders/blob/main/docs/examples/ranking_tfx.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/recommenders/blob/main/docs/examples/ranking_tfx.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/recommenders/docs/examples/ranking_tfx.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VuwrlnvQJ5k",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook-based tutorial, we will create and run a [TFX pipeline](https://www.tensorflow.org/tfx)\n",
    "to train a ranking model to predict movie ratings using TensorFlow Recommenders (TFRS).\n",
    "The pipeline will consist of three essential TFX components: ExampleGen,\n",
    "Trainer and Pusher. The pipeline includes the most minimal ML workflow like\n",
    "importing data, training a model and exporting the trained TFRS ranking model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDnPgN8UJtzN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check the TensorFlow and TFX versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jh7vKSRqPHb",
    "outputId": "d316e143-fc86-493e-ec2e-43181bee8e7c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 21:53:04.960289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \n",
      "2022-07-19 21:53:04.960315: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.2\n",
      "TFX version: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "from tfx import v1 as tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDtLdSkvqPHe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set up variables\n",
    "\n",
    "There are some variables used to define a pipeline. You can customize these\n",
    "variables as you want. By default all output from the pipeline will be\n",
    "generated under the current directory. Instead of using the SchemaGen component to generate a schema, for this\n",
    "tutorial we will create a hardcoded schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EcUseqJaE2XN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/DCN-iterate\n",
      "pipeline/pipelines/DCN-iterate\n",
      "pipeline/metadata/DCN-iterate/metadata.db\n",
      "pipeline/serving_model/DCN-iterate\n",
      "pipeline/pipelines/DCN-iterate/plots\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "PIPELINE_NAME = 'DCN-iterate'\n",
    "WORKING_DIR = 'bachelor_2022/artifact'\n",
    "PIPE_DIR = 'pipeline'\n",
    "\n",
    "# Directory where MovieLens 100K rating data resides\n",
    "DATA_ROOT = os.path.join('data', PIPELINE_NAME)\n",
    "print(DATA_ROOT)\n",
    "# Output directory to store artifacts generated from the pipeline.\n",
    "PIPELINE_ROOT = os.path.join(PIPE_DIR, 'pipelines', PIPELINE_NAME)\n",
    "print(PIPELINE_ROOT)\n",
    "# Path to a SQLite DB file to use as an MLMD storage.\n",
    "METADATA_PATH = os.path.join(PIPE_DIR, 'metadata', PIPELINE_NAME, 'metadata.db')\n",
    "print(METADATA_PATH)\n",
    "# Output directory where created models from the pipeline will be exported.\n",
    "SERVING_MODEL_DIR = os.path.join(PIPE_DIR, 'serving_model', PIPELINE_NAME)\n",
    "print(SERVING_MODEL_DIR)\n",
    "\n",
    "MODEL_PLOTS = os.path.join(PIPE_DIR, 'pipelines', PIPELINE_NAME, 'plots')\n",
    "print(MODEL_PLOTS)\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)  # Set default logging level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/DCN-iterate\n"
     ]
    }
   ],
   "source": [
    "print(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASpoNmxKSQjI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Take a quick look at the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-eSz28UDSnlG",
    "outputId": "d00e061d-e2fc-4358-c7fd-3e00e5bbc684",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'data/DCN-iterate/ml-100k_colab.csv' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!head {DATA_ROOT}/ml-100k_colab.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTtQNq1DdVvG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You should be able to see four values. For example, the first example means user '196' gives a rating of 3 to movie '242'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH6gizcpSwWV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create a pipeline\n",
    "\n",
    "TFX pipelines are defined using Python APIs. We will define a pipeline which\n",
    "consists of following three components.\n",
    "- CsvExampleGen: Reads in data files and convert them to TFX internal format\n",
    "for further processing. There are multiple\n",
    "[ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen)s for various\n",
    "formats. In this tutorial, we will use CsvExampleGen which takes CSV file input.\n",
    "- Trainer: Trains an ML model.\n",
    "[Trainer component](https://www.tensorflow.org/tfx/guide/trainer) requires a\n",
    "model definition code from users. You can use TensorFlow APIs to specify how to\n",
    "train a model and save it in a _saved_model_ format.\n",
    "- Pusher: Copies the trained model outside of the TFX pipeline.\n",
    "[Pusher component](https://www.tensorflow.org/tfx/guide/pusher) can be thought\n",
    "of an deployment process of the trained ML model.\n",
    "\n",
    "Before actually define the pipeline, we need to write a model code for the\n",
    "Trainer component first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOjDv93eS5xV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Write model training code\n",
    "\n",
    "We will build a simple ranking model to predict movie ratings. This model training code will be saved to a separate file.\n",
    "\n",
    "In this tutorial we will use\n",
    "[Generic Trainer](https://www.tensorflow.org/tfx/guide/trainer#generic_trainer)\n",
    "of TFX which support Keras-based models. You need to write a Python file\n",
    "containing `run_fn` function, which is the entrypoint for the `Trainer`\n",
    "component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aES7Hv5QTDK3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_trainer_module_file = 'dcn_ranking_training.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFsQCOytiidq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The ranking model we use is almost exactly the same as in the [Basic Ranking](https://www.tensorflow.org/recommenders/examples/basic_ranking) tutorial. The only difference is that we use movie IDs instead of movie titles in the candidate tower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gnc67uQNTDfW",
    "outputId": "06f4ccb2-d0f5-4cae-e4f8-98317f7d29c9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dcn_ranking_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_trainer_module_file}\n",
    "\n",
    "from typing import Dict, Text\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "import tensorflow_recommenders as tfrs\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "\n",
    "_FEATURE_KEYS = [\"movie_id\",\"user_id\",\"user_gender\", \"user_occupation\", \"user_age_cohort\"]\n",
    "_LABEL_KEY = 'user_rating'\n",
    "\n",
    "_FEATURE_SPEC = {\n",
    "    **{\n",
    "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
    "        for feature in _FEATURE_KEYS\n",
    "    }, _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    # Define the dimension the features should be embedded in (Dim of vector representation of each feature)\n",
    "    embedding_dimension = 32\n",
    "    self.embedding_dims = embedding_dimension\n",
    "    # Create np array with incrementing values as the vocabulary\n",
    "    unique_user_ids = np.array(range(943)).astype(str)\n",
    "    unique_movie_ids = np.array(range(1682)).astype(str)\n",
    "    unique_occupation_ids = np.array(range(21)).astype(str)\n",
    "    unique_gender_ids = np.array(range(2)).astype(str)\n",
    "    unique_age_ids = np.array(range(7)).astype(str)\n",
    "\n",
    "\n",
    "    ## String values embeddings\n",
    "    # Compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,), name='user_id', dtype=tf.int64),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.as_string(x)),\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "        # Input of 943 dims -->  Embedding of 32 dims\n",
    "        tf.keras.layers.Embedding(\n",
    "            len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for movies.\n",
    "    self.movie_embeddings = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,), name='movie_id', dtype=tf.int64),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.as_string(x)),\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_movie_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(\n",
    "            len(unique_movie_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for occupations.\n",
    "    self.occupation_embeddings = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,), name='user_occupation', dtype=tf.int64),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.as_string(x)),\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_occupation_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(\n",
    "            len(unique_occupation_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    ## Int value embeddings\n",
    "    # Compute embeddings for gender.\n",
    "    self.gender_embeddings = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,), name='user_gender', dtype=tf.int64),\n",
    "        tf.keras.layers.IntegerLookup(\n",
    "            vocabulary=unique_gender_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(\n",
    "            len(unique_gender_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for age.\n",
    "    self.age_embeddings = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1,), name='user_age_cohort', dtype=tf.int64),\n",
    "        tf.keras.layers.IntegerLookup(\n",
    "            vocabulary=unique_age_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(\n",
    "            len(unique_age_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Cross Layer\n",
    "    self.cross_layer = tfrs.layers.dcn.Cross()\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = tf.keras.Sequential([\n",
    "        self.cross_layer,\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    user_id, movie_id, user_gender, user_occupation, user_age = inputs\n",
    "\n",
    "    # Calculate embedding for each feature and save in *_embedding variable\n",
    "    user_embedding = self.user_embeddings(user_id)\n",
    "    movie_embedding = self.movie_embeddings(movie_id)\n",
    "    gender_embedding = self.gender_embeddings(user_gender)\n",
    "    occupation_embedding = self.occupation_embeddings(user_occupation)\n",
    "    age_embedding = self.age_embeddings(user_age)\n",
    "\n",
    "\n",
    "    # Create embedding layer\n",
    "    return self.ratings(tf.concat([user_embedding, movie_embedding, gender_embedding, occupation_embedding, age_embedding], axis=2))\n",
    "\n",
    "\n",
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.ranking_model: tf.keras.Model = RankingModel()\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    return self.ranking_model((features['user_id'], features['movie_id'], features['user_gender'], features['user_occupation'], features['user_age_cohort']))\n",
    "\n",
    "  def compute_loss(self,\n",
    "                   features: Dict[Text, tf.Tensor],\n",
    "                   training=False) -> tf.Tensor:\n",
    "\n",
    "    labels = features[1]\n",
    "    rating_predictions = self(features[0])\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(labels=labels, predictions=rating_predictions)\n",
    "\n",
    "\n",
    "def _input_fn(file_pattern: List[str],\n",
    "              data_accessor: tfx.components.DataAccessor,\n",
    "              schema: schema_pb2.Schema,\n",
    "              batch_size: int = 256) -> tf.data.Dataset:\n",
    "  return data_accessor.tf_dataset_factory(\n",
    "      file_pattern,\n",
    "      tfxio.TensorFlowDatasetOptions(\n",
    "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
    "      schema=schema).repeat()\n",
    "\n",
    "\n",
    "def _build_keras_model() -> tf.keras.Model:\n",
    "  return MovielensModel()\n",
    "\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "  \"\"\"Train the model based on given args.\n",
    "\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "\n",
    "  # Generate training logfiles for tensorboard\n",
    "  from datetime import datetime\n",
    "  logdir = \"pipeline/pipelines/DCN-iterate/logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "  # Derive data schema from generated _FEATURE_SPEC dictionary\n",
    "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
    "\n",
    "  train_dataset = _input_fn(\n",
    "      fn_args.train_files, fn_args.data_accessor, schema, batch_size=8192)\n",
    "  eval_dataset = _input_fn(\n",
    "      fn_args.eval_files, fn_args.data_accessor, schema, batch_size=4096)\n",
    "\n",
    "  model = _build_keras_model()\n",
    "\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      epochs = 3,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps,\n",
    "      callbacks=[tensorboard_callback])\n",
    "\n",
    "  model.save(fn_args.serving_model_dir)\n",
    "\n",
    "\n",
    "  ###  Display model summary & save plot of model architecture\n",
    "  print(\"\\n#####################################\")\n",
    "  print(model.summary())\n",
    "  print()\n",
    "  model_num = fn_args.serving_model_dir.split(\"/\")[-2]   # extract model number\n",
    "  img_dir = fn_args.custom_config[\"plot_path\"] + f\"/{model_num}\"\n",
    "  print(img_dir)\n",
    "  Path(img_dir).mkdir(parents=True, exist_ok=True)\n",
    "  tf.keras.utils.plot_model(model, to_file=f\"{img_dir}/model_architecture_{model_num}.png\", show_shapes=True)\n",
    "  print()\n",
    "\n",
    "  ### Cross feature Visualization\n",
    "  mat = model.ranking_model.cross_layer._dense.kernel # Cross weights matrix\n",
    "  features = _FEATURE_KEYS\n",
    "\n",
    "  block_norm = np.ones([len(features), len(features)])\n",
    "  dim = model.ranking_model.embedding_dims\n",
    "\n",
    "  # Compute the norms of the blocks. (revert 32 dimensional feature embedding to 1D)\n",
    "  for i in range(len(features)):\n",
    "    for j in range(len(features)):\n",
    "      block = mat[i * dim:(i + 1) * dim,\n",
    "                  j * dim:(j + 1) * dim]\n",
    "      block_norm[i,j] = np.linalg.norm(block, ord=\"fro\")\n",
    "  # Create plot\n",
    "  plt.figure(figsize=(9,9))\n",
    "  im = plt.matshow(block_norm, cmap=plt.cm.Blues)\n",
    "  ax = plt.gca()\n",
    "  divider = make_axes_locatable(plt.gca())\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "  plt.colorbar(im, cax=cax)\n",
    "  cax.tick_params(labelsize=10)\n",
    "  _ = ax.set_xticklabels([\"\"] + features, rotation=45, ha=\"left\", fontsize=10)\n",
    "  _ = ax.set_yticklabels([\"\"] + features, fontsize=10)\n",
    "\n",
    "  plt.savefig(f\"{img_dir}/cross_features_{model_num}\", dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blaw0rs-emEf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now you have completed all preparation steps to build the TFX pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3OkNz3gTLwM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Write a pipeline definition\n",
    "\n",
    "We define a function to create a TFX pipeline. A `Pipeline` object\n",
    "represents a TFX pipeline which can be run using one of pipeline\n",
    "orchestration systems that TFX supports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "M49yYVNBTPd4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     module_file: str, serving_model_dir: str,\n",
    "                     metadata_path: str, plot_path: str) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a three component pipeline with TFX.\"\"\"\n",
    "  # Brings data into the pipeline.\n",
    "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
    "\n",
    "  # Uses user-provided Python function that trains a model.\n",
    "  trainer = tfx.components.Trainer(\n",
    "      module_file=module_file,\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      train_args=tfx.proto.TrainArgs(num_steps=12),\n",
    "      eval_args=tfx.proto.EvalArgs(num_steps=24),\n",
    "      custom_config={\"plot_path\": plot_path})\n",
    "\n",
    "  # Pushes the model to a filesystem destination.\n",
    "  pusher = tfx.components.Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      push_destination=tfx.proto.PushDestination(\n",
    "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "              base_directory=serving_model_dir)))\n",
    "\n",
    "  # Following three components will be included in the pipeline.\n",
    "  components = [\n",
    "      example_gen,\n",
    "      trainer,\n",
    "      pusher,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      metadata_connection_config=tfx.orchestration.metadata\n",
    "      .sqlite_metadata_connection_config(metadata_path),\n",
    "      components=components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJbq07THU2GV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run the pipeline\n",
    "\n",
    "TFX supports multiple orchestrators to run pipelines.\n",
    "In this tutorial we will use `LocalDagRunner` which is included in the TFX\n",
    "Python package and runs pipelines on local environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mp0AkmrPdUb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we create a `LocalDagRunner` and pass a `Pipeline` object created from the\n",
    "function we already defined.\n",
    "\n",
    "The pipeline runs directly and you can see logs for the progress of the pipeline including ML model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "fAtfOZTYWJu-",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "53fa7d90-a1fc-4704-ed2a-45f56488fa0b",
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Generating ephemeral wheel package for '/home/cory/PycharmProjects/bachelor_2022/artifact/dcn_ranking_training.py' (including modules: ['dcn_ranking_training', 'tfrs_ranking_trainer']).\n",
      "INFO:absl:User module package has hash fingerprint version 425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80.\n",
      "INFO:absl:Executing: ['/home/cory/anaconda3/envs/bachelor_2022/bin/python', '/tmp/tmpiyqm5e8d/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpptt4qii4', '--dist-dir', '/tmp/tmpv1bwa8r8']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying dcn_ranking_training.py -> build/lib\n",
      "copying tfrs_ranking_trainer.py -> build/lib\n",
      "installing to /tmp/tmpptt4qii4\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/tfrs_ranking_trainer.py -> /tmp/tmpptt4qii4\n",
      "copying build/lib/dcn_ranking_training.py -> /tmp/tmpptt4qii4\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cory/anaconda3/envs/bachelor_2022/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "INFO:absl:Successfully built user code wheel distribution at 'pipeline/pipelines/DCN-iterate/_wheels/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3-none-any.whl'; target user module is 'dcn_ranking_training'.\n",
      "INFO:absl:Full user module path is 'dcn_ranking_training@pipeline/pipelines/DCN-iterate/_wheels/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3-none-any.whl'\n",
      "INFO:absl:Using deployment config:\n",
      " executor_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"Pusher\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.pusher.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"Trainer\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metadata_connection_config {\n",
      "  database_connection_config {\n",
      "    sqlite {\n",
      "      filename_uri: \"pipeline/metadata/DCN-iterate/metadata.db\"\n",
      "      connection_mode: READWRITE_OPENCREATE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using connection config:\n",
      " sqlite {\n",
      "  filename_uri: \"pipeline/metadata/DCN-iterate/metadata.db\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "INFO:absl:Component CsvExampleGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-19T23:05:03.196045\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"data/DCN-iterate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /tmp/tmpptt4qii4/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3.8.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpptt4qii4/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80.dist-info/WHEEL\n",
      "creating '/tmp/tmpv1bwa8r8/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3-none-any.whl' and adding '/tmp/tmpptt4qii4' to it\n",
      "adding 'dcn_ranking_training.py'\n",
      "adding 'tfrs_ranking_trainer.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80.dist-info/RECORD'\n",
      "removing /tmp/tmpptt4qii4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:select span and version = (0, None)\n",
      "INFO:absl:latest span and version = (0, None)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 94\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=94, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipeline/pipelines/DCN-iterate/CsvExampleGen/examples/94\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:2617288,xor_checksum:1658143009,sum_checksum:1658143009\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"DCN-iterate:2022-07-19T23:05:03.196045:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "name: \"DCN-iterate:2022-07-19T23:05:03.196045:CsvExampleGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}), exec_properties={'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 2,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_data_format': 6, 'input_base': 'data/DCN-iterate', 'output_file_format': 5, 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:2617288,xor_checksum:1658143009,sum_checksum:1658143009'}, execution_output_uri='pipeline/pipelines/DCN-iterate/CsvExampleGen/.system/executor_execution/94/executor_output.pb', stateful_working_dir='pipeline/pipelines/DCN-iterate/CsvExampleGen/.system/stateful_working_dir/2022-07-19T23:05:03.196045', tmp_dir='pipeline/pipelines/DCN-iterate/CsvExampleGen/.system/executor_execution/94/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-19T23:05:03.196045\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"data/DCN-iterate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"DCN-iterate\"\n",
      ", pipeline_run_id='2022-07-19T23:05:03.196045')\n",
      "INFO:absl:Generating examples.\n",
      "INFO:absl:Processing input csv data data/DCN-iterate/* to TFExample.\n",
      "INFO:absl:Examples generated.\n",
      "INFO:absl:Value type <class 'NoneType'> of key version in exec_properties is not supported, going to drop it\n",
      "INFO:absl:Value type <class 'list'> of key _beam_pipeline_args in exec_properties is not supported, going to drop it\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 94 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipeline/pipelines/DCN-iterate/CsvExampleGen/examples/94\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:2617288,xor_checksum:1658143009,sum_checksum:1658143009\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"DCN-iterate:2022-07-19T23:05:03.196045:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"DCN-iterate:2022-07-19T23:05:03.196045:CsvExampleGen:examples:0\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}) for execution 94\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component CsvExampleGen is finished.\n",
      "INFO:absl:Component Trainer is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-19T23:05:03.196045\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"DCN-iterate\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-07-19T23:05:03.196045\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"DCN-iterate.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\\"plot_path\\\": \\\"pipeline/pipelines/DCN-iterate/plots\\\"}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 24\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"dcn_ranking_training@pipeline/pipelines/DCN-iterate/_wheels/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 12\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 95\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=95, input_dict={'examples': [Artifact(artifact: id: 105\n",
      "type_id: 15\n",
      "uri: \"pipeline/pipelines/DCN-iterate/CsvExampleGen/examples/94\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:2617288,xor_checksum:1658143009,sum_checksum:1658143009\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"DCN-iterate:2022-07-19T23:05:03.196045:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"DCN-iterate:2022-07-19T23:05:03.196045:CsvExampleGen:examples:0\"\n",
      "create_time_since_epoch: 1658264731722\n",
      "last_update_time_since_epoch: 1658264731722\n",
      ", artifact_type: id: 15\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"pipeline/pipelines/DCN-iterate/Trainer/model/95\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"DCN-iterate:2022-07-19T23:05:03.196045:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "name: \"DCN-iterate:2022-07-19T23:05:03.196045:Trainer:model:0\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"pipeline/pipelines/DCN-iterate/Trainer/model_run/95\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"DCN-iterate:2022-07-19T23:05:03.196045:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "name: \"DCN-iterate:2022-07-19T23:05:03.196045:Trainer:model_run:0\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}), exec_properties={'eval_args': '{\\n  \"num_steps\": 24\\n}', 'module_path': 'dcn_ranking_training@pipeline/pipelines/DCN-iterate/_wheels/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3-none-any.whl', 'custom_config': '{\"plot_path\": \"pipeline/pipelines/DCN-iterate/plots\"}', 'train_args': '{\\n  \"num_steps\": 12\\n}'}, execution_output_uri='pipeline/pipelines/DCN-iterate/Trainer/.system/executor_execution/95/executor_output.pb', stateful_working_dir='pipeline/pipelines/DCN-iterate/Trainer/.system/stateful_working_dir/2022-07-19T23:05:03.196045', tmp_dir='pipeline/pipelines/DCN-iterate/Trainer/.system/executor_execution/95/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-19T23:05:03.196045\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"DCN-iterate\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-07-19T23:05:03.196045\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"DCN-iterate.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\\"plot_path\\\": \\\"pipeline/pipelines/DCN-iterate/plots\\\"}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 24\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"dcn_ranking_training@pipeline/pipelines/DCN-iterate/_wheels/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 12\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"DCN-iterate\"\n",
      ", pipeline_run_id='2022-07-19T23:05:03.196045')\n",
      "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
      "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "INFO:absl:udf_utils.get_fn {'eval_args': '{\\n  \"num_steps\": 24\\n}', 'module_path': 'dcn_ranking_training@pipeline/pipelines/DCN-iterate/_wheels/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3-none-any.whl', 'custom_config': '{\"plot_path\": \"pipeline/pipelines/DCN-iterate/plots\"}', 'train_args': '{\\n  \"num_steps\": 12\\n}'} 'run_fn'\n",
      "INFO:absl:Installing 'pipeline/pipelines/DCN-iterate/_wheels/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/home/cory/anaconda3/envs/bachelor_2022/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpz2z6g3o3', 'pipeline/pipelines/DCN-iterate/_wheels/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3-none-any.whl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./pipeline/pipelines/DCN-iterate/_wheels/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully installed 'pipeline/pipelines/DCN-iterate/_wheels/tfx_user_code_Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_age_cohort has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_age_cohort has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_age_cohort has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-Trainer\n",
      "Successfully installed tfx-user-code-Trainer-0.0+425b6ea689aff76e39c80f23b8904fbd4cc8a7180e7ec8c846d1b6e5689c9d80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_age_cohort has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cory/anaconda3/envs/bachelor_2022/lib/python3.8/site-packages/numpy/core/numeric.py:2449: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 3s 157ms/step - root_mean_squared_error: 2.7017 - loss: 6.8432 - regularization_loss: 0.0000e+00 - total_loss: 6.8432 - val_root_mean_squared_error: 1.2186 - val_loss: 1.7323 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.7323\n",
      "Epoch 2/3\n",
      "12/12 [==============================] - 2s 134ms/step - root_mean_squared_error: 1.1326 - loss: 1.2905 - regularization_loss: 0.0000e+00 - total_loss: 1.2905 - val_root_mean_squared_error: 1.1436 - val_loss: 1.3429 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.3429\n",
      "Epoch 3/3\n",
      "12/12 [==============================] - 1s 128ms/step - root_mean_squared_error: 1.1024 - loss: 1.2115 - regularization_loss: 0.0000e+00 - total_loss: 1.2115 - val_root_mean_squared_error: 1.1173 - val_loss: 1.3743 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.3743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as ranking_10_layer_call_fn, ranking_10_layer_call_and_return_conditional_losses, dense_layer_call_fn, dense_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipeline/pipelines/DCN-iterate/Trainer/model/95/Format-Serving/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipeline/pipelines/DCN-iterate/Trainer/model/95/Format-Serving/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################\n",
      "Model: \"movielens_model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ranking_model_10 (RankingMo  multiple                 168609    \n",
      " del)                                                            \n",
      "                                                                 \n",
      " ranking_10 (Ranking)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,609\n",
      "Trainable params: 168,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "pipeline/pipelines/DCN-iterate/plots/95\n",
      "\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0719 23:05:42.571378466     682 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "E0719 23:05:42.614424932     682 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "/home/cory/PycharmProjects/bachelor_2022/artifact/dcn_ranking_training.py:231: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  _ = ax.set_xticklabels([\"\"] + features, rotation=45, ha=\"left\", fontsize=10)\n",
      "/home/cory/PycharmProjects/bachelor_2022/artifact/dcn_ranking_training.py:232: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  _ = ax.set_yticklabels([\"\"] + features, fontsize=10)\n",
      "INFO:absl:Training complete. Model written to pipeline/pipelines/DCN-iterate/Trainer/model/95/Format-Serving. ModelRun written to pipeline/pipelines/DCN-iterate/Trainer/model_run/95\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 95 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"pipeline/pipelines/DCN-iterate/Trainer/model/95\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"DCN-iterate:2022-07-19T23:05:03.196045:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"DCN-iterate:2022-07-19T23:05:03.196045:Trainer:model:0\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"pipeline/pipelines/DCN-iterate/Trainer/model_run/95\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"DCN-iterate:2022-07-19T23:05:03.196045:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"DCN-iterate:2022-07-19T23:05:03.196045:Trainer:model_run:0\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}) for execution 95\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Trainer is finished.\n",
      "INFO:absl:Component Pusher is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-19T23:05:03.196045\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"DCN-iterate\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-07-19T23:05:03.196045\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"DCN-iterate.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"pipeline/serving_model/DCN-iterate\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 96\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=96, input_dict={'model': [Artifact(artifact: id: 106\n",
      "type_id: 18\n",
      "uri: \"pipeline/pipelines/DCN-iterate/Trainer/model/95\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"DCN-iterate:2022-07-19T23:05:03.196045:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"DCN-iterate:2022-07-19T23:05:03.196045:Trainer:model:0\"\n",
      "create_time_since_epoch: 1658264743364\n",
      "last_update_time_since_epoch: 1658264743364\n",
      ", artifact_type: id: 18\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipeline/pipelines/DCN-iterate/Pusher/pushed_model/96\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"DCN-iterate:2022-07-19T23:05:03.196045:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      "name: \"DCN-iterate:2022-07-19T23:05:03.196045:Pusher:pushed_model:0\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}), exec_properties={'custom_config': 'null', 'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"pipeline/serving_model/DCN-iterate\"\\n  }\\n}'}, execution_output_uri='pipeline/pipelines/DCN-iterate/Pusher/.system/executor_execution/96/executor_output.pb', stateful_working_dir='pipeline/pipelines/DCN-iterate/Pusher/.system/stateful_working_dir/2022-07-19T23:05:03.196045', tmp_dir='pipeline/pipelines/DCN-iterate/Pusher/.system/executor_execution/96/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2022-07-19T23:05:03.196045\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"DCN-iterate.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"DCN-iterate\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2022-07-19T23:05:03.196045\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"DCN-iterate.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"pipeline/serving_model/DCN-iterate\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"DCN-iterate\"\n",
      ", pipeline_run_id='2022-07-19T23:05:03.196045')\n",
      "WARNING:absl:Pusher is going to push the model without validation. Consider using Evaluator or InfraValidator in your pipeline.\n",
      "INFO:absl:Model version: 1658264743\n",
      "INFO:absl:Model written to serving path pipeline/serving_model/DCN-iterate/1658264743.\n",
      "INFO:absl:Model pushed to pipeline/pipelines/DCN-iterate/Pusher/pushed_model/96.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 96 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipeline/pipelines/DCN-iterate/Pusher/pushed_model/96\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"DCN-iterate:2022-07-19T23:05:03.196045:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.8.0\"\n",
      "  }\n",
      "}\n",
      "name: \"DCN-iterate:2022-07-19T23:05:03.196045:Pusher:pushed_model:0\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}) for execution 96\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Pusher is finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 648x648 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 288x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfx.orchestration.LocalDagRunner().run(\n",
    "  _create_pipeline(\n",
    "      pipeline_name=PIPELINE_NAME,\n",
    "      pipeline_root=PIPELINE_ROOT,\n",
    "      data_root=DATA_ROOT,\n",
    "      module_file=_trainer_module_file,\n",
    "      serving_model_dir=SERVING_MODEL_DIR,\n",
    "      metadata_path=METADATA_PATH,\n",
    "      plot_path=MODEL_PLOTS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppERq0Mj6xvW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You should see \"INFO:absl:Component Pusher is finished.\" at the end of the\n",
    "logs if the pipeline finished successfully. Because `Pusher` component is the\n",
    "last component of the pipeline.\n",
    "\n",
    "The pusher component pushes the trained model to the `SERVING_MODEL_DIR` which\n",
    "is the `serving_model/TFRS-ranking` directory if you did not change the\n",
    "variables in the previous steps. You can see the result from the file browser\n",
    "in the left-side panel in Colab, or using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTHROkqX6yHx",
    "outputId": "0f0ec5bd-9977-4a94-aa7c-72a793d3f819",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# List files in created model directory.\n",
    "!ls -R {SERVING_MODEL_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8HQfT-ziids",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can test the ranking model by computing predictions for a user and a movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EDMkz8Wiidt",
    "outputId": "7d4b8506-18b2-4d40-b58e-2744c67f6940",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "# Load the latest model for testing\n",
    "loaded = tf.saved_model.load(max(glob.glob(os.path.join(SERVING_MODEL_DIR, '*/')), key=os.path.getmtime))\n",
    "print(loaded({'user_id': [[42]], 'movie_id': [[15]], 'user_gender': [[1]], 'user_occupation': [[0]], 'user_age_cohort': [[0]]}).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08R8qvweThRf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This concludes the TensorFlow Recommenders + TFX tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "DjUA6S30k52h"
   ],
   "name": "ranking_tfx.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}